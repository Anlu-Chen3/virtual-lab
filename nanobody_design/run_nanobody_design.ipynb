{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from virtual_lab.agent import Agent\n",
    "from virtual_lab.constants import CONSISTENT_TEMPERATURE, CREATIVE_TEMPERATURE\n",
    "from virtual_lab.prompts import (\n",
    "    CODING_RULES,\n",
    "    REWRITE_PROMPT,\n",
    "    SCIENTIFIC_CRITIC,\n",
    "    create_merge_prompt,\n",
    ")\n",
    "from virtual_lab.run_meeting import run_meeting\n",
    "from virtual_lab.utils import load_summaries"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc186057c8dcc3a8",
   "metadata": {},
   "source": [
    "# Set up key parameters\n",
    "num_iterations = 5\n",
    "num_rounds = 3\n",
    "save_dir = Path(\"discussions\")\n",
    "model = \"gpt-4o-2024-08-06\"\n",
    "background_prompt = \"You are working on a research project to use machine learning to develop antibodies or nanobodies for the newest variant of the SARS-CoV-2 spike protein that also, ideally, have activity against other circulating minor variants and past variants.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Team selection",
   "id": "a9259ddc2710488f"
  },
  {
   "cell_type": "code",
   "id": "c55d79aa92e377b5",
   "metadata": {},
   "source": [
    "# Team selection - prompts\n",
    "team_selection_dir = save_dir / \"team_selection\"\n",
    "\n",
    "team_selection_agenda = f\"\"\"{background_prompt} You need to select a team of three scientists to help you with this project. Please select the team members that you would like to invite to a discussion to create the antibody/nanobody design approach. Please list the team members in the following format, using the team member below as an example. You should not include yourself (Principal Investigator) in the list.\n",
    "\n",
    "Agent(\n",
    "    title=\"Principal Investigator\",\n",
    "    expertise=\"applying artificial intelligence to biomedical research\",\n",
    "    goal=\"perform research in your area of expertise that maximizes the scientific impact of the work\",\n",
    "    role=\"lead a team of experts to solve an important problem in artificial intelligence for biomedicine, make key decisions about the project direction based on team member input, and manage the project timeline and resources\",\n",
    ")\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "PRINCIPAL_INVESTIGATOR = Agent(\n",
    "    title=\"Principal Investigator\",\n",
    "    expertise=\"applying artificial intelligence to biomedical research\",\n",
    "    goal=\"perform research in your area of expertise that maximizes the scientific impact of the work\",\n",
    "    role=\"lead a team of experts to solve an important problem in artificial intelligence for biomedicine, make key decisions about the project direction based on team member input, and manage the project timeline and resources\",\n",
    ")"
   ],
   "id": "5c2a20e3352662c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "50722e4dadc135d8",
   "metadata": {},
   "source": [
    "# Team selection - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=PRINCIPAL_INVESTIGATOR,\n",
    "            agenda=team_selection_agenda,\n",
    "            save_dir=team_selection_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f1c023cebeaaf883",
   "metadata": {},
   "source": [
    "# Team selection - merge\n",
    "team_selection_summaries = load_summaries(discussion_paths=list(team_selection_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(team_selection_summaries)}\")\n",
    "\n",
    "team_selection_merge_prompt = create_merge_prompt(agenda=team_selection_agenda)\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=PRINCIPAL_INVESTIGATOR,\n",
    "    summaries=team_selection_summaries,\n",
    "    agenda=team_selection_merge_prompt,\n",
    "    save_dir=team_selection_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d9186ce198c1b0b",
   "metadata": {},
   "source": [
    "# Add team members\n",
    "IMMUNOLOGIST = Agent(\n",
    "    title=\"Immunologist\",\n",
    "    expertise=\"antibody engineering and immune response characterization\",\n",
    "    goal=\"guide the development of antibodies/nanobodies that elicit a strong and broad immune response\",\n",
    "    role=\"advise on immunogenicity, cross-reactivity with other variants, and potential for therapeutic application, ensuring the designs are viable for experimental validation and downstream applications\",\n",
    ")\n",
    "\n",
    "MACHINE_LEARNING_SPECIALIST = Agent(\n",
    "    title=\"Machine Learning Specialist\",\n",
    "    expertise=\"developing algorithms for protein-ligand interactions and optimization\",\n",
    "    goal=\"create and apply machine learning models to predict antibody efficacy and optimize binding affinity across SARS-CoV-2 variants\",\n",
    "    role=\"lead the development of AI tools for predicting interactions and refining antibody designs based on computational results\",\n",
    ")\n",
    "\n",
    "COMPUTATIONAL_BIOLOGIST = Agent(\n",
    "    title=\"Computational Biologist\",\n",
    "    expertise=\"protein structure prediction and molecular dynamics simulations\",\n",
    "    goal=\"develop predictive models to identify potential antibody/nanobody candidates and simulate interactions with the SARS-CoV-2 spike protein\",\n",
    "    role=\"provide insights into structural dynamics, guide virtual screening efforts, and validate computational predictions with simulations\",\n",
    ")\n",
    "\n",
    "team_members = (\n",
    "    IMMUNOLOGIST,\n",
    "    MACHINE_LEARNING_SPECIALIST,\n",
    "    COMPUTATIONAL_BIOLOGIST,\n",
    "    SCIENTIFIC_CRITIC,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Projects specification",
   "id": "3804141d0b26537"
  },
  {
   "cell_type": "code",
   "id": "9df84a9e45d31bbe",
   "metadata": {},
   "source": [
    "# Project specification - prompts\n",
    "project_specification_dir = save_dir / \"project_specification\"\n",
    "\n",
    "project_specification_agenda = f\"{background_prompt} Please create an antibody/nanobody design approach to solve this problem. Decide whether you will design antibodies or nanobodies. For your choice, decide whether you will design the antibodies/nanobodies de novo or whether you will modify existing antibodies/nanobodies. If modifying existing antibodies/nanobodies, please specify which antibodies/nanobodies to start with as good candidates for targeting the newest variant of the SARS-CoV-2 spike protein. If designing antibodies/nanobodies de novo, please describe how you will propose antibody/nanobody candidates.\"\n",
    "\n",
    "project_specification_questions = (\n",
    "    \"Will you design standard antibodies or nanobodies?\",\n",
    "    \"Will you design antibodies/nanobodies de novo or will you modify existing antibodies/nanobodies (choose only one)?\",\n",
    "    \"If modifying existing antibodies/nanobodies, which precise antibodies/nanobodies will you modify (please list 3-4)?\",\n",
    "    \"If designing antibodies/nanobodies de novo, how exactly will you propose antibody/nanobody candidates?\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ff509ba8824b8ac",
   "metadata": {},
   "source": [
    "# Project specification - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=PRINCIPAL_INVESTIGATOR,\n",
    "            team_members=team_members,\n",
    "            agenda=project_specification_agenda,\n",
    "            agenda_questions=project_specification_questions,\n",
    "            save_dir=project_specification_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e66e0cfa85f2176d",
   "metadata": {},
   "source": [
    "# Project specification - merge\n",
    "project_specification_summaries = load_summaries(discussion_paths=list(project_specification_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(project_specification_summaries)}\")\n",
    "\n",
    "project_specification_merge_prompt = create_merge_prompt(\n",
    "    agenda=project_specification_agenda,\n",
    "    agenda_questions=project_specification_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=PRINCIPAL_INVESTIGATOR,\n",
    "    summaries=project_specification_summaries,\n",
    "    agenda=project_specification_merge_prompt,\n",
    "    save_dir=project_specification_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "nanobody_prompt = \"Your team previous decided to modify existing nanobodies to improve their binding to the newest variant of the SARS-CoV-2 spike protein.\"",
   "id": "7a6be070a3f8a14a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tools Selection",
   "id": "7e5307d354d28011"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Tools selection - prompts\n",
    "tools_selection_dir = save_dir / \"tools_selection\"\n",
    "\n",
    "tools_selection_agenda = f\"{background_prompt} {nanobody_prompt} Now you need to select machine learning and/or computational tools to implement this nanobody design approach. Please list several tools (5-10) that would be relevant to this nanobody design approach and how they could be used in the context of this project. If selecting machine learning tools, please prioritize pre-trained models (e.g., pre-trained protein language models or protein structure prediction models) for simplicity.\"\n",
    "\n",
    "tools_selection_questions = (\n",
    "    \"What machine learning and/or computational tools could be used for this nanobody design approach (list 5-10)?\",\n",
    "    \"For each tool, how could it be used for designing modified nanobodies?\",\n",
    ")\n",
    "\n",
    "tools_selection_prior_summaries = load_summaries(discussion_paths=[project_specification_dir / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(tools_selection_prior_summaries)}\")"
   ],
   "id": "a001a2ca1ea13a4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Tools selection - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=PRINCIPAL_INVESTIGATOR,\n",
    "            team_members=team_members,\n",
    "            summaries=tools_selection_prior_summaries,\n",
    "            agenda=tools_selection_agenda,\n",
    "            agenda_questions=tools_selection_questions,\n",
    "            save_dir=tools_selection_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "id": "a95de22d2f1d277b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Tools selection - merge\n",
    "tools_selection_summaries = load_summaries(discussion_paths=list(tools_selection_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(tools_selection_summaries)}\")\n",
    "\n",
    "tools_selection_merge_prompt = create_merge_prompt(\n",
    "    agenda=tools_selection_agenda,\n",
    "    agenda_questions=tools_selection_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=PRINCIPAL_INVESTIGATOR,\n",
    "    summaries=tools_selection_summaries,\n",
    "    agenda=tools_selection_merge_prompt,\n",
    "    save_dir=tools_selection_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ],
   "id": "580378a119b0cce5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementation",
   "id": "c3777aacd05e6e17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Implementation - prompts\n",
    "implementation_agent_selection_dir = save_dir / \"implementation_agent_selection\"\n",
    "\n",
    "implementation_agent_selection_agenda = f\"{background_prompt} {nanobody_prompt} Your team needs to build three components of a nanobody design pipeline: ESM, AlphaFold-Multimer, and Rosetta. For each component, please select the team member who will implement the component. A team member may implement more than one component.\"\n",
    "\n",
    "implementation_agent_selection_questions = (\n",
    "    \"Which team member will implement ESM?\",\n",
    "    \"Which team member will implement AlphaFold-Multimer?\",\n",
    "    \"Which team member will implement Rosetta?\",\n",
    ")\n",
    "\n",
    "implementation_agent_selection_prior_summaries = load_summaries(discussion_paths=[team_selection_dir / \"merged.json\", project_specification_dir / \"merged.json\", tools_selection_dir / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(implementation_agent_selection_prior_summaries)}\")"
   ],
   "id": "a4b45d33467d1405",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Implementation - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=PRINCIPAL_INVESTIGATOR,\n",
    "            summaries=implementation_agent_selection_prior_summaries,\n",
    "            agenda=implementation_agent_selection_agenda,\n",
    "            agenda_questions=implementation_agent_selection_questions,\n",
    "            save_dir=implementation_agent_selection_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "id": "777c7f17e1853145",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Implementation - merge\n",
    "implementation_agent_selection_summaries = load_summaries(discussion_paths=list(implementation_agent_selection_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(implementation_agent_selection_summaries)}\")\n",
    "\n",
    "implementation_agent_selection_merge_prompt = create_merge_prompt(\n",
    "    agenda=implementation_agent_selection_agenda,\n",
    "    agenda_questions=implementation_agent_selection_questions\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=PRINCIPAL_INVESTIGATOR,\n",
    "    summaries=implementation_agent_selection_summaries,\n",
    "    agenda=implementation_agent_selection_merge_prompt,\n",
    "    save_dir=implementation_agent_selection_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "b741ab035e21003c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ESM",
   "id": "9b1ac62cf9a8f39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ESM - prompts\n",
    "esm_dir = save_dir / \"esm\"\n",
    "\n",
    "esm_agenda = f\"{background_prompt} {nanobody_prompt} Now you must use ESM to suggest modifications to an existing antibody. Please write a complete Python script that takes a nanobody sequence as input and uses ESM amino acid log-likelihoods to identify the most promising point mutations by log-likelihood ratio.\""
   ],
   "id": "1b2b6e3a180a548e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ESM - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=MACHINE_LEARNING_SPECIALIST,\n",
    "            agenda=esm_agenda,\n",
    "            agenda_rules=CODING_RULES,\n",
    "            save_dir=esm_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "id": "e0affb5cd00bec96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ESM - merge\n",
    "esm_summaries = load_summaries(discussion_paths=list(esm_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(esm_summaries)}\")\n",
    "\n",
    "esm_merge_prompt = create_merge_prompt(\n",
    "    agenda=esm_agenda,\n",
    "    agenda_rules=CODING_RULES,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=MACHINE_LEARNING_SPECIALIST,\n",
    "    summaries=esm_summaries,\n",
    "    agenda=esm_merge_prompt,\n",
    "    save_dir=esm_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "6b0936e225dcc32f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Improve ESM",
   "id": "9cf7a7a3d2b7b7fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Improve ESM - prompts\n",
    "improve_esm_agenda = f\"\"\"You previously wrote a Python script that uses ESM to compute the log-likelihood ratio of point mutations in a nanobody sequence (see summary). {REWRITE_PROMPT}\n",
    "\n",
    "1. Replace \"facebook/esm1b-t33_650M_UR50S\" with \"facebook/esm1b_t33_650M_UR50S\".\n",
    "2. Run the calculations of the mutant log-likelihoods by iterating through the sequences in batches of 16.\n",
    "3. Add a progress bar to the batched mutant log-likelihood calculations.\n",
    "4. Run the mutant log-likelihood calculations on CUDA but with no gradients.\n",
    "5. Load the nanobody sequence from a user-specified CSV file that has the columns \"sequence\" and \"name\". Adapt your code to run the mutant log-likelihood calculations on all sequences in the CSV file one-by-one.\n",
    "6. For each sequence, save the mutant log-likelihoods to a CSV file with the format \"mutated_sequence,position,original_aa,mutated_aa,log_likelihood_ratio\". Ask the user for a save directory and then save this CSV file in that directory with the name: <nanbody-name>.csv.\"\"\""
   ],
   "id": "b062e9cb5f92a482",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Improve ESM - discussion\n",
    "improve_esm_summaries = load_summaries(discussion_paths=list(esm_dir.glob(\"merged.json\")))\n",
    "print(f\"Number of summaries: {len(improve_esm_summaries)}\")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=MACHINE_LEARNING_SPECIALIST,\n",
    "    summaries=improve_esm_summaries,\n",
    "    agenda=improve_esm_agenda,\n",
    "    save_dir=esm_dir,\n",
    "    save_name=\"improved\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "6388c95f9e77d811",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### AlphaFold-Multimer",
   "id": "9ba22302ea18a575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# AlphaFold-Multimer - prompts\n",
    "alphafold_dir = save_dir / \"alphafold\"\n",
    "\n",
    "alphafold_agenda = f\"{background_prompt} {nanobody_prompt} Now you must use AlphaFold-Multimer to predict the structure of a nanobody-antigen complex and evaluate its binding. I will run AlphaFold-Multimer on several nanobody-antigen complexes and you need to process the outputs. Please write a complete Python script that takes as input a directory containing PDB files where each PDB file contains one nanobody-antigen complex predicted by AlphaFold-Multimer and outputs a CSV file containing the AlphaFold-Multimer confidence of each nanobody-antigen complex in terms of the interface pLDDT.\""
   ],
   "id": "9588993af806c3f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# AlphaFold-Multimer - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=COMPUTATIONAL_BIOLOGIST,\n",
    "            agenda=alphafold_agenda,\n",
    "            agenda_rules=CODING_RULES,\n",
    "            save_dir=alphafold_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "id": "1ca49b4e29ac8b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# AlphaFold-Multimer - merge\n",
    "alphafold_summaries = load_summaries(discussion_paths=list(alphafold_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(alphafold_summaries)}\")\n",
    "\n",
    "alphafold_merge_prompt = create_merge_prompt(\n",
    "    agenda=alphafold_agenda,\n",
    "    agenda_rules=CODING_RULES,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=COMPUTATIONAL_BIOLOGIST,\n",
    "    summaries=alphafold_summaries,\n",
    "    agenda=alphafold_merge_prompt,\n",
    "    save_dir=alphafold_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "d03e25b1ecad9557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Improve AlphaFold-Multimer",
   "id": "619858f6ff3335c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Improve AlphaFold-Multimer - prompts\n",
    "improve_alphafold_agenda = f\"\"\"You previously wrote a Python script that processes the outputs of AlphaFold-Multimer to calculate the confidence of nanobody-antigen complexes (see summary). {REWRITE_PROMPT}\n",
    "\n",
    "1. Replace the current imports of Chain and Residue with \"from Bio.PDB.Chain import Chain\" and \"from Bio.PDB.Residue import Residue\".\n",
    "2. Remove the logging setup and simply print any log messages to the console.\n",
    "3. Replace the parallel processing with sequential processing to avoid getting an \"OSError: Too many open files\".\n",
    "4. Change the list of pdb_files to instead get all PDB files in the directory that follow the pattern \"**/*unrelaxed_rank_001*.pdb\".\n",
    "5. Change the calculation of average pLDDT to divide by the number of atoms rather than the number of residues.\n",
    "6. Return and save in the CSV both the number of residues and the number of atoms in the interface.\n",
    "7. Change the default distance threshold to 4.\"\"\""
   ],
   "id": "dd78a537e8608abb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Improve AlphaFold-Multimer - discussion\n",
    "improve_alphafold_summaries = load_summaries(discussion_paths=list(alphafold_dir.glob(\"merged.json\")))\n",
    "print(f\"Number of summaries: {len(improve_alphafold_summaries)}\")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=COMPUTATIONAL_BIOLOGIST,\n",
    "    summaries=improve_alphafold_summaries,\n",
    "    agenda=improve_alphafold_agenda,\n",
    "    save_dir=alphafold_dir,\n",
    "    save_name=\"improved\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "9d9bf62680e027cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rosetta",
   "id": "7ba34f13b0ec3889"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rosetta - prompts\n",
    "rosetta_dir = save_dir / \"rosetta\"\n",
    "\n",
    "rosetta_agenda = f\"{background_prompt} {nanobody_prompt} Now you must use Rosetta to calculate the binding energy of nanobody-antigen complexes. You must do this in three parts. First, write a complete RosettaScripts XML file that calculates the binding energy of a nanobody-antigen complex as provided in PDB format, including any necessary preprocessing steps for the complex. Second, write an example command that uses Rosetta to run this RosettaScripts XML file on a given PDB file to calculate the binding energy and save it to a score file. Third, write a complete Python script that takes as input a directory with multiple Rosetta binding energy score files and outputs a single CSV file with the names and scores of each of the individual files in sorted order (highest to lowest score).\""
   ],
   "id": "38b7c084b07dd169",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rosetta - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=COMPUTATIONAL_BIOLOGIST,\n",
    "            agenda=rosetta_agenda,\n",
    "            agenda_rules=CODING_RULES,\n",
    "            save_dir=rosetta_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "id": "3433242b9472cd28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rosetta - merge\n",
    "rosetta_summaries = load_summaries(discussion_paths=list(rosetta_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(rosetta_summaries)}\")\n",
    "\n",
    "rosetta_merge_prompt = create_merge_prompt(\n",
    "    agenda=rosetta_agenda,\n",
    "    agenda_rules=CODING_RULES,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=COMPUTATIONAL_BIOLOGIST,\n",
    "    summaries=rosetta_summaries,\n",
    "    agenda=rosetta_merge_prompt,\n",
    "    save_dir=rosetta_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "4563b6d0b6116f2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Improve Rosetta",
   "id": "4771524f6b0c8270"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Improve Rosetta XML - prompts\n",
    "improve_rosetta_xml_agenda = f\"\"\"You previously wrote a RosettaScripts XML file to calculate the binding affinity of a nanobody-antigen complex (see summary). {REWRITE_PROMPT}\n",
    "\n",
    "1. Replace \"ref15.wts\" with \"ref2015.wts\".\n",
    "2. Remove the InterfaceEnergy filter since it is not valid in Rosetta.\n",
    "3. Replace the entire output tag (including any nested tags) with <OUTPUT scorefxn=\"ref15\"/>.\"\"\""
   ],
   "id": "a03ce8ff3dc2c718",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Improve Rosetta XML - discussion\n",
    "improve_rosetta_xml_summaries = load_summaries(discussion_paths=list(rosetta_dir.glob(\"merged.json\")))\n",
    "print(f\"Number of summaries: {len(improve_rosetta_xml_summaries)}\")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=COMPUTATIONAL_BIOLOGIST,\n",
    "    summaries=improve_rosetta_xml_summaries,\n",
    "    agenda=improve_rosetta_xml_agenda,\n",
    "    save_dir=rosetta_dir,\n",
    "    save_name=\"improved_xml\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "d92fb27857e97f52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Improve Rosetta Python - prompts\n",
    "improve_rosetta_python_agenda = f\"\"\"You previously wrote a Python script to aggregate multiple Rosetta binding energy score files into one CSV file (see summary). {REWRITE_PROMPT}\n",
    "\n",
    "1. Modify the extract_scores_from_file function so that it extracts the dG_separated value from a file of the following form.\n",
    "\n",
    "SEQUENCE:\n",
    "SCORE: total_score complex_normalized           dG_cross dG_cross/dSASAx100 dG_separated dG_separated/dSASAx100 dSASA_hphobic dSASA_int dSASA_polar delta_unsatHbonds dslf_fa13    fa_atr    fa_dun   fa_elec fa_intra_rep fa_intra_sol_xover4              fa_rep              fa_sol hbond_E_fraction hbond_bb_sc hbond_lr_bb    hbond_sc hbond_sr_bb hbonds_int lk_ball_wtd    nres_all    nres_int       omega     p_aa_pp    packstat per_residue_energy_int pro_close rama_prepro         ref    sc_value side1_normalized side1_score side2_normalized side2_score yhh_planarity description\n",
    "SCORE:    -990.807             -2.914            -21.436             -1.857      -21.436                 -1.857       774.274  1154.088     379.813            12.000    -3.867 -1928.622   376.416  -541.777        3.745              54.944             265.303            1052.322            0.053     -84.023    -130.532     -54.069     -46.266      1.000     -41.725     340.000      55.000      39.977     -81.331       0.000                 -2.699     2.349      -6.870     131.513       0.000           -2.236     -51.431           -3.031     -97.008         1.706 KP3_Ty1-G59Y_unrelaxed_rank_001_alphafold2_multimer_v3_model_3_seed_000_0001\"\"\""
   ],
   "id": "48ed12daeae0cf1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Improve Rosetta Python - discussion\n",
    "improve_rosetta_python_summaries = load_summaries(discussion_paths=list(rosetta_dir.glob(\"merged.json\")))\n",
    "print(f\"Number of summaries: {len(improve_rosetta_python_summaries)}\")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=COMPUTATIONAL_BIOLOGIST,\n",
    "    summaries=improve_rosetta_python_summaries,\n",
    "    agenda=improve_rosetta_python_agenda,\n",
    "    save_dir=rosetta_dir,\n",
    "    save_name=\"improved_python\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "ea4287f833216ee9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Workflow Design",
   "id": "a050fffc08866b10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Workflow design - prompts\n",
    "workflow_design_dir = save_dir / \"workflow_design\"\n",
    "\n",
    "workflow_design_agenda = f\"{background_prompt} {nanobody_prompt} Your team has built three components of a nanobody design pipeline: ESM, AlphaFold-Multimer, and Rosetta. Each of these three tools can be used to score a nanobody mutation based on how the mutation affects binding to an antigen. Your goal is to start with an existing nanobody and iteratively add mutations to it to improve its binding to the newest variant of the SARS-CoV-2 spike protein, resulting in 24 modified nanobodies with one or more mutations. Please determine how to use ESM, AlphaFold-Multimer, and Rosetta in this iterative design process. An important constraint is that ESM can evaluate all potential mutations to a nanobody in 5 minutes while AlphaFold-Multimer takes 30 minutes per mutation and Rosetta takes five minutes per mutation. The whole iterative process should take no more than a few days to complete. Note that AlphaFold-Multimer must be run before Rosetta on each mutation since Rosetta requires the nanobody-antigen structure predicted by AlphaFold-Multimer. Additionally, note that ESM log-likelihood ratios are generally in the range of 5-10 (higher is better), AlphaFold-Multimer interface pLDDT confidence scores are generally in the range of 60-80 (higher is better), and Rosetta binding energy scores are generally in the range of -20 to -40 (lower is better).\"\n",
    "\n",
    "workflow_design_questions = (\n",
    "    \"In each iteration, what is the order of operations for evaluating mutations with ESM, AlphaFold-Multimer, and Rosetta?\",\n",
    "    \"In each iteration, how many mutations (give a single number) will you evaluate with ESM, AlphaFold-Multimer, and Rosetta?\",\n",
    "    \"At the end of each iteration, how will you weigh the ESM, AlphaFold-Multimer, and/or Rosetta scores (give a formula) to rank the nanobody mutations?\",\n",
    "    \"At the end of each iteration, how many of the top-ranked mutations (give a single number) will you keep for the next round?\",\n",
    "    \"How will you decide how many iterations of mutations to run?\",\n",
    "    \"After all of the iterations are complete, how exactly (step-by-step) will you select the final set of 24 modified nanobodies from across the iterations for experimental validation?\",\n",
    ")"
   ],
   "id": "c55ec9669eeee9fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Workflow design - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=PRINCIPAL_INVESTIGATOR,\n",
    "            agenda=workflow_design_agenda,\n",
    "            agenda_questions=workflow_design_questions,\n",
    "            save_dir=workflow_design_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "id": "3210bdc6d68bd0bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Workflow design - merge\n",
    "workflow_design_summaries = load_summaries(discussion_paths=list(workflow_design_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(workflow_design_summaries)}\")\n",
    "\n",
    "workflow_design_merge_prompt = create_merge_prompt(\n",
    "    agenda=workflow_design_agenda,\n",
    "    agenda_questions=workflow_design_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=PRINCIPAL_INVESTIGATOR,\n",
    "    summaries=workflow_design_summaries,\n",
    "    agenda=workflow_design_merge_prompt,\n",
    "    save_dir=workflow_design_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "cb4534d4913ecf88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Nanobody Improvement",
   "id": "e0fe689c393aa94d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Summary of experimental results\n",
    "experimental_results_summary = \"\"\"Your team has designed 92 mutated nanobodies (23 each for the wild-type nanobodies H11-D4, Nb21, Ty1, and VHH-72) to improve their binding to the KP.3 variant of the SARS-CoV-2 spike protein receptor binding domain (RBD). Each nanobody has 1-4 mutations relative to the wild-type nanobody. Your team used ESM log-likelihood ratios (ESM LLR) to score the nanobody mutations independent of the antigen, AlphaFold-Multimer to predict the structure of the mutated nanobody in complex with the KP.3 RBD and compute the interface pLDDT (AF ipLDDT) as a metric of binding confidence, and Rosetta to calculate the binding energy of the mutated nanobody in complex with the KP.3 RBD (RS dG) based on the AlphaFold-Multimer predicted structure followed by a Rosetta relaxation. You have ranked the mutant nanobodies and selected the top ones using a weighted score of WS = 0.2 * (ESM LLR) + 0.5 * (AF ipLDDT) - 0. 3 * (RS dG). The 92 selected nanobodies were tested along with the four wild-type nanobodies using an ELISA assay to measure binding to the Wuhan, JN.1, KP.3, KP2.3, and BA.2 strains of the SARS-CoV-2 spike RBD. Note that the JN.1 strain is closely related to KP.3 and KP2.3. BSA was used as a negative control. Most of the mutated nanobodies showed at least moderate expression levels. The ELISA results are as follows:\n",
    "\n",
    "H11-D4: The wild-type only binds to the Wuhan RBD. Most mutants show binding to the Wuhan RBD as well, including one with a higher binding level than the wild-type. However, that mutant and two others bind non-specifically to the negative control BSA along with other strains of the SARS-CoV-2 RBD. No mutant nanobody shows specific binding to any strain other than the Wuhan RBD.\n",
    "\n",
    "Nb21: The wild-type only binds to the Wuhan RBD. All mutant nanobodies also bind to the Wuhan RBD. There are no non-specific binders. One mutant nanobody with mutations I77V, L59E, Q87A, and R37Q binds to the Wuhan RBD (strong binding), the JN.1 RBD (moderate binding), and the KP.3 RBD (weak binding). Thus, this mutant introduces specific binding to JN.1 and KP.3 that the wild-type does not possess, and it increases binding to the Wuhan RBD.\n",
    "\n",
    "Ty1: The wild-type only binds to the Wuhan RBD. Many mutant nanobodies do not show binding, but several show moderate binding to the Wuhan RBD. One mutant nanobody with mutations V32F, G59D, N45S, and F32S binds to the Wuhan RBD (strong binding) and the JN.1 RBD (moderate binding). This mutant introduces specific binding to JN.1 that the wild-type does not possess, and it increases binding to the Wuhan RBD. Additionally, there are is one mutant with weak, non-specific binding to BSA and other RBD strains.\n",
    "\n",
    "VHH-72: The wild-type only binds to the Wuhan RBD. Most mutants show binding to the Wuhan RBD as well, including several with a higher binding level than the wild-type. Two mutant nanobodies bind non-specifically to BSA and several RBD strains. No mutant nanobody shows specific binding to any strain other than the Wuhan RBD.\"\"\""
   ],
   "id": "a65a5f7c0bb819b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Nanobody improvement - prompts\n",
    "nanobody_improvement_dir = save_dir / \"nanobody_improvement\"\n",
    "\n",
    "nanobody_improvement_agenda = f\"\"\"{background_prompt} {nanobody_prompt} {experimental_results_summary}\n",
    "\n",
    "Based on these results, you must decide how to proceed to design further improved nanobodies for recent variants of SARS-CoV-2. You may either continue to pursue identifying binders to the KP.3 RBD or you may decide to target a different strain or strains of the SARS-CoV-2 spike RBD. Your team should select another 92 mutant nanobodies to test experimentally. This time, you do not have to test an equal number of mutants for each wild-type nanobody, and you may even entirely leave out some wild-type nanobodies. You can either start again from the wild-type nanobodies and introduce mutations or begin with one of the previously designed nanobodies. You may use ESM, AlphaFold-Multimer, and Rosetta in similar ways as your previous design process, or you can change the design workflow. As a reminder, ESM is antigen-agnostic and improves general nanobody quality while AlphaFold-Multimer and Rosetta are antigen-specific and focus on binding to the selected antigen. You should aim to design nanobodies that bind specifically to the RBD of recent variants of SARS-CoV-2 and do not bind non-specifically to BSA. You should provide a rationale for all of your decisions.\"\"\"\n",
    "\n",
    "nanobody_improvement_questions = (\n",
    "    \"Will you continue to target the KP.3 RBD or will you target a different strain or strains of the SARS-CoV-2 spike RBD?\",\n",
    "    \"Which wild-type nanobody or nanobodies will you select for further improvement?\",\n",
    "    \"How many mutant nanobodies will you design for each of those wild-type nanobodies (92 total)?\",\n",
    "    \"Will you begin with the wild-type nanobody itself and introduce mutations, or will you begin with one of the previously designed mutant nanobodies?\",\n",
    "    \"If you are beginning with previously designed mutant nanobodies, which one or ones will you start with?\",\n",
    "    \"Will you continue to use the same general ESM, AlphaFold-Multimer, and Rosetta design pipeline you previously used, or will you design a new computational pipeline?\",\n",
    ")\n",
    "\n",
    "nanobody_improvement_prior_summaries = load_summaries(discussion_paths=[workflow_design_dir / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(nanobody_improvement_prior_summaries)}\")"
   ],
   "id": "7802ef1937c2552b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Nanobody improvement - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"team\",\n",
    "            team_lead=PRINCIPAL_INVESTIGATOR,\n",
    "            team_members=team_members,\n",
    "            summaries=nanobody_improvement_prior_summaries,\n",
    "            agenda=nanobody_improvement_agenda,\n",
    "            agenda_questions=nanobody_improvement_questions,\n",
    "            save_dir=nanobody_improvement_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "            num_rounds=num_rounds,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "id": "784c5f53610c1cbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Nanobody improvement - merge\n",
    "nanobody_improvement_summaries = load_summaries(discussion_paths=list(nanobody_improvement_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(nanobody_improvement_summaries)}\")\n",
    "\n",
    "nanobody_improvement_merge_prompt = create_merge_prompt(\n",
    "    agenda=nanobody_improvement_agenda,\n",
    "    agenda_questions=nanobody_improvement_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=PRINCIPAL_INVESTIGATOR,\n",
    "    summaries=nanobody_improvement_summaries,\n",
    "    agenda=nanobody_improvement_merge_prompt,\n",
    "    save_dir=nanobody_improvement_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    "    num_rounds=num_rounds,\n",
    ")"
   ],
   "id": "54b15b15f8057122",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Updated Workflow",
   "id": "e9ebc9991e4104ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Updated workflow - prompts\n",
    "updated_workflow_dir = save_dir / \"updated_workflow\"\n",
    "\n",
    "updated_workflow_agenda = f\"\"\"{background_prompt} {nanobody_prompt} {experimental_results_summary}\n",
    "\n",
    "Your team has decided to design further improved nanobodies for recent variants of SARS-CoV-2 as described in the summary using the same general ESM, AlphaFold-Multimer, and Rosetta computational design pipeline. ESM will again be used to evaluate the overall quality of mutated nanobodies while AlphaFold-Multimer and Rosetta will be used to determine their specific binding to your selected SARS-CoV-2 variants. Now, you need to specify more details for this updated design workflow.\"\"\"\n",
    "\n",
    "updated_workflow_questions = (\n",
    "    \"When using ESM to evaluate all single point mutations to an input nanobody sequence, how many of the top ranked mutations by ESM LLR will you keep for analysis by AlphaFold-Multimer and Rosetta out of the ~2,000 possible mutations?\",\n",
    "    \"If this number differs from your previous design process, what is the rationale for the change?\",\n",
    "    \"After evaluating those mutated nanobodies with ESM, AlphaFold-Multimer, and Rosetta, what formula will you use to compute a weighted score (WS) for each mutated nanobody, and how will this factor in binding to both the JN.1 and KP.3 RBDs for the AlphaFold-Multimer and Rosetta portions of the score?\",\n",
    "    \"If this WS formula differs from your previous design process, what is the rationale for the change?\",\n",
    "    \"After computing the WS for each mutated nanobody, how many of the top ranked mutated nanobodies will you select for the next round of mutation?\",\n",
    "    \"If this number differs from your previous design process, what is the rationale for the change?\",\n",
    "    \"How many rounds of mutation will you run in total starting with the Nb21 and Ty1 mutants?\",\n",
    "    \"If this number differs from your previous design process, what is the rationale for the change?\",\n",
    ")\n",
    "\n",
    "updated_workflow_prior_summaries = load_summaries(discussion_paths=[workflow_design_dir / \"merged.json\", nanobody_improvement_dir / \"merged.json\"])\n",
    "print(f\"Number of prior summaries: {len(updated_workflow_prior_summaries)}\")"
   ],
   "id": "af2aeef39965c96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Updated workflow - discussion\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=PRINCIPAL_INVESTIGATOR,\n",
    "            summaries=updated_workflow_prior_summaries,\n",
    "            agenda=updated_workflow_agenda,\n",
    "            agenda_questions=updated_workflow_questions,\n",
    "            save_dir=updated_workflow_dir,\n",
    "            save_name=f\"discussion_{iteration_num + 1}\",\n",
    "            temperature=CREATIVE_TEMPERATURE,\n",
    "            model=model,\n",
    "        ) for iteration_num in range(num_iterations)\n",
    "    ])"
   ],
   "id": "77716528cd51472a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Updated workflow - merge\n",
    "updated_workflow_summaries = load_summaries(discussion_paths=list(updated_workflow_dir.glob(\"discussion_*.json\")))\n",
    "print(f\"Number of summaries: {len(updated_workflow_summaries)}\")\n",
    "\n",
    "updated_workflow_merge_prompt = create_merge_prompt(\n",
    "    agenda=updated_workflow_agenda,\n",
    "    agenda_questions=updated_workflow_questions,\n",
    ")\n",
    "\n",
    "run_meeting(\n",
    "    meeting_type=\"individual\",\n",
    "    team_member=PRINCIPAL_INVESTIGATOR,\n",
    "    summaries=updated_workflow_summaries,\n",
    "    agenda=updated_workflow_merge_prompt,\n",
    "    save_dir=updated_workflow_dir,\n",
    "    save_name=\"merged\",\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    "    model=model,\n",
    ")"
   ],
   "id": "b7d153994b7f39b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Virtual Lab Analysis",
   "id": "bb5b2c7839b930aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "id": "74d3a3d37081ed02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "figure_dir = Path(\"figures/virtual_lab_analysis\")\n",
    "figure_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "phase_to_agent_to_word_count = {}"
   ],
   "id": "8bebeb39ba3c3b0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count words that the human user wrote\n",
    "phase_to_human_words = {\n",
    "    \"team_selection\":  [\n",
    "        background_prompt,\n",
    "        PRINCIPAL_INVESTIGATOR.prompt,\n",
    "        SCIENTIFIC_CRITIC.prompt,\n",
    "        team_selection_agenda.replace(f\"{background_prompt} \", \"\"),\n",
    "    ],\n",
    "    \"project_specification\": [\n",
    "        project_specification_agenda.replace(f\"{background_prompt} \", \"\"),\n",
    "        *project_specification_questions,\n",
    "        nanobody_prompt,\n",
    "    ],\n",
    "    \"tools_selection\": [\n",
    "        tools_selection_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        *tools_selection_questions,\n",
    "    ],\n",
    "    \"implementation_agent_selection\": [\n",
    "        implementation_agent_selection_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        *implementation_agent_selection_questions,\n",
    "    ],\n",
    "    \"esm\": [\n",
    "        esm_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        improve_esm_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "    ],\n",
    "    \"alphafold\": [\n",
    "        alphafold_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        improve_alphafold_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "    ],\n",
    "    \"rosetta\": [\n",
    "        rosetta_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        improve_rosetta_xml_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "        improve_rosetta_python_agenda.replace(f\" {REWRITE_PROMPT}\", \"\"),\n",
    "    ],\n",
    "    \"workflow_design\": [\n",
    "        workflow_design_agenda.replace(f\"{background_prompt} {nanobody_prompt} \", \"\"),\n",
    "        *workflow_design_questions,\n",
    "    ],\n",
    "}\n",
    "\n",
    "for phase, human_words in phase_to_human_words.items():\n",
    "    phase_to_agent_to_word_count[phase] = {\"Human Researcher\": len(\" \".join(human_words).split())}"
   ],
   "id": "3577d08c72a2aeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count words that the LLM agents wrote\n",
    "for phase_dir in [team_selection_dir, project_specification_dir, tools_selection_dir, implementation_agent_selection_dir, esm_dir, alphafold_dir, rosetta_dir, workflow_design_dir]:\n",
    "    phase_name = phase_dir.name\n",
    "\n",
    "    print(f\"Phase: {phase_name}\")\n",
    "\n",
    "    # Load the text written by each agent\n",
    "    agent_to_text = {}\n",
    "    for path in phase_dir.glob(\"*.json\"):\n",
    "        with open(path) as f:\n",
    "            discussion = json.load(f)\n",
    "\n",
    "        for message in discussion:\n",
    "            agent_to_text.setdefault(message[\"agent\"], []).append(message[\"message\"])\n",
    "\n",
    "    # Count the number of words written by each agent\n",
    "    for agent, text in agent_to_text.items():\n",
    "        if agent == \"User\":\n",
    "            continue\n",
    "\n",
    "        agent_to_text[agent] = \" \".join(text)\n",
    "        word_count = len(agent_to_text[agent].split())\n",
    "        phase_to_agent_to_word_count[phase_name][agent] = word_count\n",
    "\n",
    "# Print words by phase\n",
    "for phase in phase_to_agent_to_word_count:\n",
    "    print(f\"Phase: {phase}\")\n",
    "    for agent, word_count in phase_to_agent_to_word_count[phase].items():\n",
    "        print(f\"Number of words written by {agent}: {word_count:,}\")\n",
    "    print()\n",
    "\n",
    "# Sum word counts across phases\n",
    "agent_to_word_count = {}\n",
    "for phase in phase_to_agent_to_word_count:\n",
    "    for agent, word_count in phase_to_agent_to_word_count[phase].items():\n",
    "        agent_to_word_count[agent] = agent_to_word_count.get(agent, 0) + word_count\n",
    "\n",
    "# Total number of words written by each LLM agent\n",
    "for agent, word_count in agent_to_word_count.items():\n",
    "    print(f\"Total number of words written by {agent}: {word_count:,}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Total number of words written by all LLM agents\n",
    "total_human_words = sum(phase_to_agent_to_word_count[phase][\"Human Researcher\"] for phase in phase_to_agent_to_word_count)\n",
    "total_agent_words = sum(word_count for agent, word_count in agent_to_word_count.items() if agent != \"Human Researcher\")\n",
    "\n",
    "print(f\"Total number of words written by Human Researcher: {total_human_words:,}\")\n",
    "print(f\"Total number of words written by all LLM agents: {total_agent_words:,}\")"
   ],
   "id": "30b622f7378bd3ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "agent_to_color = {\n",
    "    agent: sns.color_palette(\"tab10\", n_colors=len(agent_to_word_count))[i]\n",
    "    for i, agent in enumerate(agent_to_word_count)\n",
    "}"
   ],
   "id": "62dd0609f9e7274c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "ax.pie(\n",
    "    agent_to_word_count.values(),\n",
    "    labels=agent_to_word_count.keys(),\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=[agent_to_color[agent] for agent in agent_to_word_count],\n",
    ")\n",
    "ax.set_title(f\"Words written\")\n",
    "plt.savefig(figure_dir / \"total_words_written.pdf\", bbox_inches=\"tight\")"
   ],
   "id": "3a00e6cdaa1a1c05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for phase in phase_to_agent_to_word_count:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    ax.pie(\n",
    "        phase_to_agent_to_word_count[phase].values(),\n",
    "        labels=phase_to_agent_to_word_count[phase].keys(),\n",
    "        autopct=\"%1.1f%%\",\n",
    "        colors=[agent_to_color[agent] for agent in phase_to_agent_to_word_count[phase]],\n",
    "    )\n",
    "    ax.set_title(f\"Words written in {phase.replace('_', ' ')}\")\n",
    "    plt.savefig(figure_dir / f\"{phase}_words_written.pdf\", bbox_inches=\"tight\")"
   ],
   "id": "8465196358c50d9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bdefc83347336dc3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
