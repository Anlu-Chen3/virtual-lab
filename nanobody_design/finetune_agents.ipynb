{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from virtual_lab.constants import CONSISTENT_TEMPERATURE\n",
    "from virtual_lab.run_meeting import run_meeting\n",
    "from virtual_lab.utils import get_pubmed_central_article\n",
    "\n",
    "from nanobody_constants import (\n",
    "    background_prompt,\n",
    "    nanobody_prompt,\n",
    "    discussions_phase_to_dir,\n",
    "    model,\n",
    "    finetuning_base_model,\n",
    "    immunologist,\n",
    "    machine_learning_specialist,\n",
    "    computational_biologist,\n",
    ")"
   ],
   "id": "a0472e92df8ee037"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Topic to agent mapping\n",
    "topic_to_agent = {\n",
    "    \"nanobodies\": immunologist,\n",
    "    \"SARS-CoV-2 spike protein\": immunologist,\n",
    "    \"SARS-CoV-2 variants KP.3 and JN.1\": immunologist,\n",
    "    \"ESM\": machine_learning_specialist,\n",
    "    \"AlphaFold-Multimer\": computational_biologist,\n",
    "    \"Rosetta\": computational_biologist,\n",
    "}"
   ],
   "id": "164ca17b6c09fc08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Agent fine-tuning queries\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=agent,\n",
    "            agenda=f\"{background_prompt} {nanobody_prompt} You are responsible for understanding the topic \\\"{topic}\\\" in the context of designing nanobody binders for SARS-CoV-2. You need to fine-tune yourself on the relevant literature on {topic} to improve your ability to design SARS-CoV-2 nanobody binders. Please write out a series of five distinct search queries that you want to run to find relevant scientific papers on {topic}. Include both queries about {topic} generally as well as queries about how {topic} relates to designing nanobody binders for SARS-CoV-2. Please provide the queries in Python syntax as a list of strings.\",\n",
    "            agenda_questions=(\n",
    "                f\"What are the queries that you want to perform to identify the relevant literature on {topic} (as a list of strings in Python syntax)?\",),\n",
    "            save_dir=discussions_phase_to_dir[\"finetuning\"],\n",
    "            save_name=f\"{topic.replace(' ', '_')}_queries\",\n",
    "            temperature=CONSISTENT_TEMPERATURE,\n",
    "            model=model,\n",
    "        ) for topic, agent in topic_to_agent.items()\n",
    "    ])"
   ],
   "id": "2ac338d6d173bf0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Agent fine-tuning queries\n",
    "topic_to_queries = {\n",
    "    \"nanobodies\": [\n",
    "        \"nanobodies AND SARS-CoV-2 spike protein\",\n",
    "        \"nanobody engineering AND cross-reactivity AND SARS-CoV-2 variants\",\n",
    "        \"machine learning AND nanobody design AND SARS-CoV-2\",\n",
    "        \"broad-spectrum nanobodies AND coronavirus\",\n",
    "        \"nanobody optimization AND immune response AND SARS-CoV-2\"\n",
    "    ],\n",
    "    \"SARS-CoV-2 spike protein\": [\n",
    "        \"SARS-CoV-2 spike protein structure and function\",\n",
    "        \"SARS-CoV-2 spike protein variants and mutations\",\n",
    "        \"nanobody binding to SARS-CoV-2 spike protein\",\n",
    "        \"machine learning in antibody and nanobody design for SARS-CoV-2\",\n",
    "        \"cross-reactivity of nanobodies with SARS-CoV-2 spike protein variants\"\n",
    "    ],\n",
    "    \"SARS-CoV-2 variants KP.3 and JN.1\": [\n",
    "        \"SARS-CoV-2 variant KP.3 spike protein structure\",\n",
    "        \"SARS-CoV-2 variant JN.1 spike protein structure\",\n",
    "        \"nanobody design for SARS-CoV-2 variant KP.3\",\n",
    "        \"nanobody design for SARS-CoV-2 variant JN.1\",\n",
    "        \"cross-reactivity of nanobodies with SARS-CoV-2 variants KP.3 and JN.1\"\n",
    "    ],\n",
    "    \"ESM\": [\n",
    "        \"Evolutionary Scale Modeling (ESM) in protein design\",\n",
    "        \"ESM for antibody and nanobody development\",\n",
    "        \"ESM SARS-CoV-2 spike protein binding\",\n",
    "        \"Machine learning ESM nanobody design SARS-CoV-2\",\n",
    "        \"ESM optimization of nanobody binding affinity SARS-CoV-2 variants\"\n",
    "    ],\n",
    "    \"AlphaFold-Multimer\": [\n",
    "        \"AlphaFold-Multimer protein structure prediction\",\n",
    "        \"AlphaFold-Multimer SARS-CoV-2 spike protein\",\n",
    "        \"designing nanobody binders using AlphaFold-Multimer\",\n",
    "        \"AlphaFold-Multimer nanobody interaction SARS-CoV-2\",\n",
    "        \"machine learning AlphaFold-Multimer nanobody SARS-CoV-2\"\n",
    "    ],\n",
    "    \"Rosetta\": [\n",
    "        \"Rosetta software protein design\",\n",
    "        \"Rosetta nanobody design SARS-CoV-2\",\n",
    "        \"Rosetta molecular modeling SARS-CoV-2 spike protein\",\n",
    "        \"Rosetta antibody engineering SARS-CoV-2\",\n",
    "        \"Rosetta computational biology nanobody optimization\"\n",
    "    ],\n",
    "}"
   ],
   "id": "603675b18435369e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Agent fine-tuning papers\n",
    "for topic, agent in topic_to_agent.items():\n",
    "    if topic not in topic_to_queries:\n",
    "        continue\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        concurrent.futures.wait([\n",
    "            executor.submit(\n",
    "                run_meeting,\n",
    "                meeting_type=\"individual\",\n",
    "                team_member=agent,\n",
    "                agenda=f\"{background_prompt} {nanobody_prompt} You are responsible for understanding the topic \\\"{topic}\\\" in the context of designing nanobody binders for SARS-CoV-2. You need to fine-tune yourself on the relevant literature on {topic} to improve your ability to design SARS-CoV-2 nanobody binders. Please use PubMed Central and search for relevant papers on {topic} using the query \\\"{query}\\\" and request 25 articles with abstracts only. Read all of the abstracts and based on each abstract individually, decide whether you want to fine-tune yourself on the full text of that paper. Include as many papers as possible, but only include papers that are directly relevant to {topic}. Please provide the PMCIDs and titles of all the papers that you wish to fine-tune yourself on as a Python dictionary mapping PMCID as a double-quoted string to title as a double-quoted string.\",\n",
    "                agenda_questions=(\n",
    "                    \"What are the PMCIDs and titles of the papers you wish to fine-tune yourself on (as a Python dictionary mapping PMCID as a double-quoted string to title as double-quoted string)?\",),\n",
    "                save_dir=discussions_phase_to_dir[\"finetuning\"],\n",
    "                save_name=f\"{topic.replace(' ', '_')}_papers_{query_num + 1}\",\n",
    "                temperature=CONSISTENT_TEMPERATURE,\n",
    "                model=model,\n",
    "                pubmed_search=True,\n",
    "            ) for query_num, query in enumerate(topic_to_queries[topic])\n",
    "        ])"
   ],
   "id": "2ba3181c77e2e7b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Download papers from PubMed Central for fine-tuning\n",
    "pmcid_to_title_pattern = re.compile(r'\\{\\s*(\".*?\"\\s*:\\s*\".*?\"\\s*(,\\s*\".*?\"\\s*:\\s*\".*?\"\\s*)*)?\\}')\n",
    "\n",
    "for topic, agent in topic_to_agent.items():\n",
    "    pmcids, titles = set(), set()\n",
    "\n",
    "    # Get all paper paths for a topic\n",
    "    paper_paths = sorted(discussions_phase_to_dir[\"finetuning\"].glob(f\"{topic.replace(' ', '_')}_papers_*.json\"))\n",
    "\n",
    "    # Check if all papers results are present\n",
    "    if len(paper_paths) != 5:\n",
    "        print(f\"Missing papers for {topic}\")\n",
    "        continue\n",
    "\n",
    "    # Extract PMC IDs and titles from each papers file\n",
    "    for paper_path in paper_paths:\n",
    "        # Load paper discussion\n",
    "        with open(paper_path) as f:\n",
    "            paper_discussion = json.load(f)\n",
    "\n",
    "        # Extract PMC IDs and titles dictionary\n",
    "        paper_message = paper_discussion[-1][\"message\"]\n",
    "        pattern_result = pmcid_to_title_pattern.search(paper_message)\n",
    "\n",
    "        # Check if pattern matched\n",
    "        if pattern_result is None:\n",
    "            print(f\"No papers found for {paper_path}\")\n",
    "            continue\n",
    "\n",
    "        # Extract PMC IDs and titles dictionary\n",
    "        pmcid_to_title = json.loads(pattern_result.group())\n",
    "\n",
    "        # Add PMC IDs and titles to set, avoiding duplicates by title\n",
    "        for pmcid, title in pmcid_to_title.items():\n",
    "            title = title.lower()\n",
    "\n",
    "            if title not in titles:\n",
    "                pmcids.add(pmcid)\n",
    "                titles.add(title)\n",
    "\n",
    "    # Download papers by PMC ID and format for fine-tuning\n",
    "    training_data = [\n",
    "        {\"messages\": [{\"role\": \"system\", \"content\": agent.prompt},\n",
    "                      {\"role\": \"user\", \"content\": \"\"},\n",
    "                      {\"role\": \"assistant\", \"content\": paragraph}]}\n",
    "        for pmcid in sorted(pmcids) for paragraph in get_pubmed_central_article(pmcid=pmcid)[1]\n",
    "    ]\n",
    "\n",
    "    print(f\"Number of examples for {topic}: {len(training_data):,}\")\n",
    "\n",
    "    # Save training data in jsonl format\n",
    "    with open(discussions_phase_to_dir[\"finetuning\"] / f\"{topic.replace(' ', '_')}_training_data.jsonl\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(json.dumps(example) for example in training_data))"
   ],
   "id": "b94895349ed6bb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Upload fine-tuning data\n",
    "topic_to_id = {}\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "for topic in topic_to_agent:\n",
    "    path = discussions_phase_to_dir[\"finetuning\"] / f\"{topic.replace(' ', '_')}_training_data.jsonl\"\n",
    "\n",
    "    file_object = client.files.create(\n",
    "        file=open(path, \"rb\"),\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "    topic_to_id[topic] = file_object.id\n",
    "\n",
    "# Save file IDs\n",
    "with open(discussions_phase_to_dir[\"finetuning\"] / \"topic_to_id.json\", \"w\") as f:\n",
    "    json.dump(topic_to_id, f)\n",
    "file_objects = client.files.list().data\n",
    "print(f\"Found {len(file_objects)} files\")"
   ],
   "id": "ee5c062a1cd23206"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Launch fine-tuning runs\n",
    "with open(discussions_phase_to_dir[\"finetuning\"] / \"topic_to_id.json\") as f:\n",
    "    topic_to_id = json.load(f)\n",
    "\n",
    "# for topic, file_id in topic_to_id.items():\n",
    "#     client.fine_tuning.jobs.create(\n",
    "#         training_file=file_id,\n",
    "#         model=finetuning_model,\n",
    "#     )\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "    training_file=topic_to_id[\"ESM\"],\n",
    "    model=finetuning_base_model,\n",
    ")"
   ],
   "id": "7da9369b7c17cd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "list(client.fine_tuning.jobs.list())[0].status",
   "id": "66ae2d0e00cb8e3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from virtual_lab.utils import get_messages\n",
    "\n",
    "finetuned_model = \"gpt-4o-mini-2024-07-18\"\n",
    "# finetuned_model = \"ft:gpt-4o-mini-2024-07-18:personal::AlQbTW9G\"\n",
    "agent = client.beta.assistants.create(name=machine_learning_specialist.title,\n",
    "                                      instructions=machine_learning_specialist.prompt, model=finetuned_model)\n",
    "thread = client.beta.threads.create()\n",
    "client.beta.threads.messages.create(thread_id=thread.id, role=\"user\",\n",
    "                                    content=\"What are the three algorithms of the DeepRank-GNN-esm model?\")\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=agent.id,\n",
    "    model=finetuned_model,\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")\n",
    "messages = get_messages(client=client, thread_id=thread.id)\n",
    "print(messages[-1][\"content\"][0][\"text\"][\"value\"])"
   ],
   "id": "51a0bdefdd05dd63"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
