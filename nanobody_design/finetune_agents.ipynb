{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "from virtual_lab.constants import CONSISTENT_TEMPERATURE\n",
    "from virtual_lab.run_meeting import run_meeting\n",
    "from virtual_lab.utils import get_messages, get_pubmed_central_article\n",
    "\n",
    "from nanobody_constants import (\n",
    "    background_prompt,\n",
    "    nanobody_prompt,\n",
    "    discussions_phase_to_dir,\n",
    "    model,\n",
    "    finetuning_base_model,\n",
    "    immunologist,\n",
    "    machine_learning_specialist,\n",
    "    computational_biologist,\n",
    ")"
   ],
   "id": "a0472e92df8ee037",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Topic to agent mapping\n",
    "topic_to_agent = {\n",
    "    \"nanobodies\": immunologist,\n",
    "    \"SARS-CoV-2 spike protein\": immunologist,\n",
    "    \"SARS-CoV-2 variants KP.3 and JN.1\": immunologist,\n",
    "    \"ESM\": machine_learning_specialist,\n",
    "    \"AlphaFold-Multimer\": computational_biologist,\n",
    "    \"Rosetta\": computational_biologist,\n",
    "}"
   ],
   "id": "164ca17b6c09fc08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Agent fine-tuning queries\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    concurrent.futures.wait([\n",
    "        executor.submit(\n",
    "            run_meeting,\n",
    "            meeting_type=\"individual\",\n",
    "            team_member=agent,\n",
    "            agenda=f\"{background_prompt} {nanobody_prompt} You are responsible for understanding the topic \\\"{topic}\\\" in the context of designing nanobody binders for SARS-CoV-2. You need to fine-tune yourself on the relevant literature on {topic} to improve your ability to design SARS-CoV-2 nanobody binders. Please write out a series of five distinct search queries that you want to run to find relevant scientific papers on {topic}. Include both queries about {topic} generally as well as queries about how {topic} relates to designing nanobody binders for SARS-CoV-2. Please provide the queries in Python syntax as a list of double-quoted strings.\",\n",
    "            agenda_questions=(\n",
    "                f\"What are the queries that you want to perform to identify the relevant literature on {topic} (as a list of double-quoted strings in Python syntax)?\",),\n",
    "            save_dir=discussions_phase_to_dir[\"finetuning\"],\n",
    "            save_name=f\"{topic.replace(' ', '_')}_queries\",\n",
    "            temperature=CONSISTENT_TEMPERATURE,\n",
    "            model=model,\n",
    "        ) for topic, agent in topic_to_agent.items()\n",
    "    ])"
   ],
   "id": "2ac338d6d173bf0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Agent fine-tuning queries\n",
    "query_list_pattern = re.compile(r'\\[\\s*(\".*?\"\\s*(,\\s*\".*?\"\\s*)*)?,?\\s*\\]')\n",
    "\n",
    "topic_to_queries = {}\n",
    "\n",
    "for topic, agent in topic_to_agent.items():\n",
    "    # Get query path for topic\n",
    "    query_path = discussions_phase_to_dir[\"finetuning\"] / f\"{topic.replace(' ', '_')}_queries.json\"\n",
    "\n",
    "    # Load query discussion\n",
    "    with open(query_path) as f:\n",
    "        query_discussion = json.load(f)\n",
    "\n",
    "    # Extract queries\n",
    "    query_message = query_discussion[-1][\"message\"]\n",
    "    pattern_result = query_list_pattern.search(query_message)\n",
    "\n",
    "    # Check if pattern is matched\n",
    "    if pattern_result is None:\n",
    "        print(f\"No queries found for {query_path}\")\n",
    "        continue\n",
    "\n",
    "    # Extract queries\n",
    "    queries = json.loads(pattern_result.group())\n",
    "    topic_to_queries[topic] = queries\n",
    "\n",
    "print(topic_to_queries)"
   ],
   "id": "603675b18435369e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Agent fine-tuning papers\n",
    "for topic, agent in topic_to_agent.items():\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        concurrent.futures.wait([\n",
    "            executor.submit(\n",
    "                run_meeting,\n",
    "                meeting_type=\"individual\",\n",
    "                team_member=agent,\n",
    "                agenda=f\"{background_prompt} {nanobody_prompt} You are responsible for understanding the topic \\\"{topic}\\\" in the context of designing nanobody binders for SARS-CoV-2. You need to fine-tune yourself on the relevant literature on {topic} to improve your ability to design SARS-CoV-2 nanobody binders. Please use PubMed Central and search for relevant papers on {topic} using the query \\\"{query}\\\" and request 100 articles with abstracts only. Read all of the abstracts and based on each abstract individually, decide whether you want to fine-tune yourself on the full text of that paper. Include as many papers as possible, but only include papers that are directly relevant to {topic}. Please provide the PMCIDs and titles of all the papers that you wish to fine-tune yourself on as a Python dictionary mapping PMCID as a double-quoted string to title as a double-quoted string.\",\n",
    "                agenda_questions=(\n",
    "                    \"What are the PMCIDs and titles of the papers you wish to fine-tune yourself on (as a Python dictionary mapping PMCID as a double-quoted string to title as double-quoted string)?\",),\n",
    "                save_dir=discussions_phase_to_dir[\"finetuning\"],\n",
    "                save_name=f\"{topic.replace(' ', '_')}_papers_{query_num + 1}\",\n",
    "                temperature=CONSISTENT_TEMPERATURE,\n",
    "                model=model,\n",
    "                pubmed_search=True,\n",
    "            ) for query_num, query in enumerate(topic_to_queries[topic]) if not (discussions_phase_to_dir[\"finetuning\"] / f\"{topic.replace(' ', '_')}_papers_{query_num + 1}.json\").exists()\n",
    "        ])"
   ],
   "id": "2ba3181c77e2e7b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download papers from PubMed Central for fine-tuning\n",
    "pmcid_to_title_pattern = re.compile(r'\\{\\s*(\".*?\"\\s*:\\s*\".*?\"\\s*(,\\s*\".*?\"\\s*:\\s*\".*?\"\\s*)*)?\\}')\n",
    "\n",
    "for topic, agent in topic_to_agent.items():\n",
    "    pmcids, titles = set(), set()\n",
    "\n",
    "    # Get all paper paths for a topic\n",
    "    paper_paths = sorted(discussions_phase_to_dir[\"finetuning\"].glob(f\"{topic.replace(' ', '_')}_papers_*.json\"))\n",
    "\n",
    "    # Check if all papers results are present\n",
    "    if len(paper_paths) != 5:\n",
    "        print(f\"Missing papers for {topic}\")\n",
    "        continue\n",
    "\n",
    "    # Extract PMC IDs and titles from each papers file\n",
    "    for paper_path in paper_paths:\n",
    "        # Load paper discussion\n",
    "        with open(paper_path) as f:\n",
    "            paper_discussion = json.load(f)\n",
    "\n",
    "        # Extract PMC IDs and titles dictionary\n",
    "        paper_message = paper_discussion[1][\"message\"]\n",
    "        pattern_result = pmcid_to_title_pattern.search(paper_message)\n",
    "\n",
    "        # Check if pattern is matched\n",
    "        if pattern_result is None:\n",
    "            print(f\"No papers found for {paper_path}\")\n",
    "            continue\n",
    "\n",
    "        # Extract PMC IDs and titles dictionary\n",
    "        pmcid_to_title = json.loads(pattern_result.group())\n",
    "\n",
    "        # Add PMC IDs and titles to set, avoiding duplicates by title\n",
    "        for pmcid, title in pmcid_to_title.items():\n",
    "            title = title.lower()\n",
    "\n",
    "            if title not in titles:\n",
    "                pmcids.add(pmcid)\n",
    "                titles.add(title)\n",
    "\n",
    "    # Download papers by PMC ID and format for fine-tuning\n",
    "    training_data = []\n",
    "    for pmcid in tqdm(pmcids):\n",
    "        title, content = get_pubmed_central_article(pmcid=pmcid)\n",
    "\n",
    "        if title is None:\n",
    "            continue\n",
    "\n",
    "        training_data += [\n",
    "            {\"messages\": [{\"role\": \"system\", \"content\": agent.prompt},\n",
    "                          {\"role\": \"user\", \"content\": \"\"},\n",
    "                          {\"role\": \"assistant\", \"content\": paragraph}]}\n",
    "            for paragraph in [title] + content\n",
    "        ]\n",
    "\n",
    "    print(f\"Number of papers for {topic}: {len(pmcids):,}\")\n",
    "    print(f\"Number of examples for {topic}: {len(training_data):,}\")\n",
    "\n",
    "    # Save training data in jsonl format\n",
    "    with open(discussions_phase_to_dir[\"finetuning\"] / f\"{topic.replace(' ', '_')}_training_data.jsonl\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(json.dumps(example) for example in training_data))"
   ],
   "id": "b94895349ed6bb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Upload fine-tuning data\n",
    "topic_to_id = {}\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "for topic in topic_to_agent:\n",
    "    path = discussions_phase_to_dir[\"finetuning\"] / f\"{topic.replace(' ', '_')}_training_data.jsonl\"\n",
    "\n",
    "    file_object = client.files.create(\n",
    "        file=open(path, \"rb\"),\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "    topic_to_id[topic] = file_object.id\n",
    "\n",
    "# Save topic file IDs\n",
    "with open(discussions_phase_to_dir[\"finetuning\"] / \"topic_to_id.json\", \"w\") as f:\n",
    "    json.dump(topic_to_id, f)"
   ],
   "id": "ee5c062a1cd23206",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load topic file IDs\n",
    "with open(discussions_phase_to_dir[\"finetuning\"] / \"topic_to_id.json\") as f:\n",
    "    topic_to_id = json.load(f)\n",
    "\n",
    "topics = sorted(topic_to_id)"
   ],
   "id": "bb0e6da655cb759a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Launch fine-tuning jobs\n",
    "# for topic, file_id in topic_to_id.items():\n",
    "#     client.fine_tuning.jobs.create(\n",
    "#         training_file=file_id,\n",
    "#         model=finetuning_model,\n",
    "#     )\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "    training_file=topic_to_id[topics[3]],\n",
    "    model=finetuning_base_model,  # TODO: swap for GPT-4o, not mini\n",
    ")"
   ],
   "id": "7da9369b7c17cd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(client.fine_tuning.jobs.list())[0].status",
   "id": "66ae2d0e00cb8e3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up topic to fine-tuned model mapping\n",
    "topic_to_model = {}"
   ],
   "id": "295b1b032e55cc98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "finetuned_model = finetuning_base_model\n",
    "# finetuned_model = \"ft:gpt-4o-mini-2024-07-18:personal::AlQbTW9G\"\n",
    "\n",
    "agent = machine_learning_specialist\n",
    "query = \"What are the three algorithms of the DeepRank-GNN-esm model?\"\n",
    "\n",
    "assistant = client.beta.assistants.create(name=agent.title, instructions=agent.prompt, model=finetuned_model)\n",
    "thread = client.beta.threads.create()\n",
    "client.beta.threads.messages.create(thread_id=thread.id, role=\"user\",content=query)\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    model=finetuned_model,\n",
    "    temperature=CONSISTENT_TEMPERATURE,\n",
    ")\n",
    "messages = get_messages(client=client, thread_id=thread.id)\n",
    "\n",
    "print(messages[-1][\"content\"][0][\"text\"][\"value\"])"
   ],
   "id": "51a0bdefdd05dd63",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
